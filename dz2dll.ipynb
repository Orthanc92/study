{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подключаем необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as numpy\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision as tv\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tv.datasets.FashionMNIST('.', train=True, transform=tv.transforms.ToTensor(), download=True)\n",
    "test_data = tv.datasets.FashionMNIST('.', train=False, transform=tv.transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE)\n",
    "test = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создаем базовую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "trainer = optim.SGD(model.parameters(), lr=.01)\n",
    "trainer.param_groups[0]['params'] = [param.to(device) for param in trainer.param_groups[0]['params']]\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    for ep in range(num_epochs):\n",
    "        train_iters, train_passed  = 0, 0\n",
    "        train_loss, train_acc = 0., 0.\n",
    "        start=time.time()\n",
    "        \n",
    "        model.train()\n",
    "        for X, y in train:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            trainer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_loss += l.item()\n",
    "            train_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            train_iters += 1\n",
    "            train_passed += len(X)\n",
    "        \n",
    "        test_iters, test_passed  = 0, 0\n",
    "        test_loss, test_acc = 0., 0.\n",
    "        model.eval()\n",
    "        for X, y in test:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            test_loss += l.item()\n",
    "            test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            test_iters += 1\n",
    "            test_passed += len(X)\n",
    "            \n",
    "        print(\"ep: {}, taked: {:.3f}, train_loss: {}, train_acc: {}, test_loss: {}, test_acc: {}\".format(\n",
    "            ep, time.time() - start, train_loss / train_iters, train_acc / train_passed,\n",
    "            test_loss / test_iters, test_acc / test_passed)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 5.077, train_loss: 0.8753253520803249, train_acc: 0.7043666666666667, test_loss: 0.8275793567299843, test_acc: 0.7075\n",
      "ep: 1, taked: 5.026, train_loss: 0.7777534170353666, train_acc: 0.7346333333333334, test_loss: 0.7547829955816269, test_acc: 0.732\n",
      "ep: 2, taked: 5.013, train_loss: 0.7171938667906091, train_acc: 0.7553666666666666, test_loss: 0.704866062104702, test_acc: 0.7494\n",
      "ep: 3, taked: 4.975, train_loss: 0.6735299871322956, train_acc: 0.7710333333333333, test_loss: 0.6675939321517944, test_acc: 0.7644\n",
      "ep: 4, taked: 4.916, train_loss: 0.6399475944803116, train_acc: 0.7842166666666667, test_loss: 0.6386566169559955, test_acc: 0.7787\n",
      "ep: 5, taked: 4.922, train_loss: 0.6132898897566694, train_acc: 0.7944666666666667, test_loss: 0.6156390599906445, test_acc: 0.7849\n",
      "ep: 6, taked: 4.952, train_loss: 0.5916393143065433, train_acc: 0.8020166666666667, test_loss: 0.5969382591545582, test_acc: 0.792\n",
      "ep: 7, taked: 4.976, train_loss: 0.5737484343508457, train_acc: 0.80795, test_loss: 0.5815298609435559, test_acc: 0.7969\n",
      "ep: 8, taked: 4.942, train_loss: 0.5587495736619259, train_acc: 0.81305, test_loss: 0.568608558177948, test_acc: 0.8033\n",
      "ep: 9, taked: 4.947, train_loss: 0.5459784616815283, train_acc: 0.8169666666666666, test_loss: 0.5575976967811584, test_acc: 0.8065\n",
      "ep: 10, taked: 5.022, train_loss: 0.5349483374585496, train_acc: 0.8196333333333333, test_loss: 0.5480979040265084, test_acc: 0.809\n",
      "ep: 11, taked: 5.036, train_loss: 0.5253038089326088, train_acc: 0.82275, test_loss: 0.5397877179086208, test_acc: 0.8121\n",
      "ep: 12, taked: 5.119, train_loss: 0.5167784389029157, train_acc: 0.8249166666666666, test_loss: 0.532434719055891, test_acc: 0.8144\n",
      "ep: 13, taked: 4.973, train_loss: 0.5091657389985754, train_acc: 0.8273666666666667, test_loss: 0.5258744187653065, test_acc: 0.8174\n",
      "ep: 14, taked: 4.983, train_loss: 0.5023179494320078, train_acc: 0.82925, test_loss: 0.5199738755822182, test_acc: 0.8185\n",
      "ep: 15, taked: 4.988, train_loss: 0.49610625036219336, train_acc: 0.8306666666666667, test_loss: 0.5146260909736157, test_acc: 0.8201\n",
      "ep: 16, taked: 4.989, train_loss: 0.4904338782138013, train_acc: 0.8325833333333333, test_loss: 0.5097436003386975, test_acc: 0.8215\n",
      "ep: 17, taked: 4.994, train_loss: 0.4852259155283583, train_acc: 0.83425, test_loss: 0.5052682742476463, test_acc: 0.8226\n",
      "ep: 18, taked: 4.986, train_loss: 0.480421204769865, train_acc: 0.8359833333333333, test_loss: 0.5011431932449341, test_acc: 0.824\n",
      "ep: 19, taked: 4.993, train_loss: 0.4759598688876375, train_acc: 0.8374333333333334, test_loss: 0.49732387736439704, test_acc: 0.8253\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, модель недостаточно сложна и выдает низкие метрики, усложним ее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=1024, bias=True)\n",
       "  (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): ReLU()\n",
       "  (4): Dropout(p=0.5, inplace=False)\n",
       "  (5): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): ReLU()\n",
       "  (8): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ReLU()\n",
       "  (11): Dropout(p=0.5, inplace=False)\n",
       "  (12): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 1024),\n",
    "    torch.nn.BatchNorm1d(1024),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(1024, 512),\n",
    "    torch.nn.BatchNorm1d(512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(512,256),\n",
    "    torch.nn.BatchNorm1d(256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(256, 10)\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "trainer = optim.Adam(model.parameters(), lr=.01)\n",
    "trainer.param_groups[0]['params'] = [param.to(device) for param in trainer.param_groups[0]['params']]\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 5.286, train_loss: 0.5533636567440439, train_acc: 0.7988666666666666, test_loss: 0.4371093150228262, test_acc: 0.8432\n",
      "ep: 1, taked: 5.297, train_loss: 0.42300676272270527, train_acc: 0.8464666666666667, test_loss: 0.4028959147632122, test_acc: 0.8487\n",
      "ep: 2, taked: 5.267, train_loss: 0.38343917613333844, train_acc: 0.86145, test_loss: 0.3703386586159468, test_acc: 0.8616\n",
      "ep: 3, taked: 5.261, train_loss: 0.3597409171626923, train_acc: 0.86945, test_loss: 0.34804477663710714, test_acc: 0.8708\n",
      "ep: 4, taked: 5.277, train_loss: 0.3394501585275569, train_acc: 0.8754166666666666, test_loss: 0.35189390340819954, test_acc: 0.867\n",
      "ep: 5, taked: 5.260, train_loss: 0.3249080073326192, train_acc: 0.8810166666666667, test_loss: 0.3322750698775053, test_acc: 0.8782\n",
      "ep: 6, taked: 5.245, train_loss: 0.31347244648223227, train_acc: 0.88575, test_loss: 0.3339101274497807, test_acc: 0.8794\n",
      "ep: 7, taked: 5.276, train_loss: 0.30197164169017304, train_acc: 0.8892, test_loss: 0.32457662280648947, test_acc: 0.879\n",
      "ep: 8, taked: 5.287, train_loss: 0.2948253890301319, train_acc: 0.8911166666666667, test_loss: 0.32331017646938565, test_acc: 0.8812\n",
      "ep: 9, taked: 5.290, train_loss: 0.286478084198972, train_acc: 0.8954333333333333, test_loss: 0.31394960628822444, test_acc: 0.8859\n",
      "ep: 10, taked: 5.237, train_loss: 0.2776350254074056, train_acc: 0.8974, test_loss: 0.3247259619645774, test_acc: 0.8813\n",
      "ep: 11, taked: 5.233, train_loss: 0.26592444574579277, train_acc: 0.9017, test_loss: 0.31596497213467956, test_acc: 0.8848\n",
      "ep: 12, taked: 5.262, train_loss: 0.26116519811305594, train_acc: 0.9033, test_loss: 0.31767656905576586, test_acc: 0.8835\n",
      "ep: 13, taked: 5.238, train_loss: 0.25768852468500747, train_acc: 0.9048, test_loss: 0.3225865619257092, test_acc: 0.8837\n",
      "ep: 14, taked: 5.239, train_loss: 0.24845678704850216, train_acc: 0.9073, test_loss: 0.317413782607764, test_acc: 0.884\n",
      "ep: 15, taked: 5.232, train_loss: 0.24539778219892625, train_acc: 0.9083166666666667, test_loss: 0.3154893359169364, test_acc: 0.8875\n",
      "ep: 16, taked: 5.266, train_loss: 0.2371273993177617, train_acc: 0.9103, test_loss: 0.3245661439374089, test_acc: 0.8866\n",
      "ep: 17, taked: 5.245, train_loss: 0.23742656244876537, train_acc: 0.91085, test_loss: 0.30220794333145024, test_acc: 0.893\n",
      "ep: 18, taked: 5.235, train_loss: 0.22929933749614878, train_acc: 0.91385, test_loss: 0.3074045983608812, test_acc: 0.8925\n",
      "ep: 19, taked: 5.235, train_loss: 0.22371574500773816, train_acc: 0.9151166666666667, test_loss: 0.30639884024858477, test_acc: 0.8923\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, модель показала неплухую точность в 89 %"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
