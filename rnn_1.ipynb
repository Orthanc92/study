{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем сам алгоритм дешифровки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caesar_cipher(text, shift):\n",
    "    result = ''\n",
    "    for char in text:\n",
    "        if char.isalpha():\n",
    "            start = ord('а') if char.islower() else ord('А')\n",
    "            result += chr((ord(char) - start + shift) % 33 + start)\n",
    "        else:\n",
    "            result += char\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'C:\\\\Users\\\\79169\\\\Desktop\\\\voyna-i-mir-tom-1.txt'\n",
    "with open(file_path, 'rb') as file:\n",
    "    lines = []\n",
    "    for line in file:\n",
    "        try:\n",
    "            line = line.strip().decode(encoding='utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "           \n",
    "            line = line.strip().decode(encoding='windows-1251', errors='ignore')\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        lines.append(line)\n",
    "\n",
    "text = \" \".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почистим их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = re.sub(r'[^а-яА-ЯёЁ\\s]', '',text)\n",
    "cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "cleaned_text = cleaned_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем для обучения первые 10000 слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = cleaned_text[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закодируем наш текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_text = [caesar_cipher(text, shift) for text in cleaned_text]\n",
    "enc_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARS = set('абвгдеѐжзийклмнопрстуфхцчшщъыьэюя ')\n",
    "\n",
    "INDEX_TO_CHAR = ['none'] + [w for w in CHARS]\n",
    "CHAR_TO_INDEX = {w: i for i, w in enumerate(INDEX_TO_CHAR)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_TO_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CHAR_TO_INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оформим наши данные в тензоры pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 72\n",
    "X = torch.zeros((len(enc_text), MAX_LEN), dtype=int)\n",
    "for i in range(len(enc_text)):  # для каждого предложения\n",
    "    for j, w in enumerate(enc_text[i]):  # для каждого токена\n",
    "        if j >= MAX_LEN:\n",
    "            break\n",
    "        X[i, j] = CHAR_TO_INDEX.get(w, CHAR_TO_INDEX['none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [21,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [14,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [19,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [26,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctext = list(cleaned_text)\n",
    "ctext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 72\n",
    "Y = torch.zeros((len(ctext), MAX_LEN), dtype=int)\n",
    "\n",
    "for i in range(len(ctext)):  # для каждого дешифрованного предложения\n",
    "    for j, w in enumerate(ctext[i]):  # для каждого токена\n",
    "        if j >= MAX_LEN:\n",
    "            break\n",
    "        Y[i, j] = CHAR_TO_INDEX.get(w, CHAR_TO_INDEX['none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [33,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [19,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [17,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(len(CHAR_TO_INDEX), 72)  \n",
    "        self.rnn = torch.nn.RNN(72, 256, batch_first=True)\n",
    "        self.out = torch.nn.Linear(256, len(CHAR_TO_INDEX))\n",
    "\n",
    "    def forward(self, sentences, state=None):\n",
    "        x = self.embedding(sentences)\n",
    "        x, s = self.rnn(x)\n",
    "        return self.out(x)\n",
    "\n",
    "model = Network()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "X = X.to(device)\n",
    "Y = Y.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим ее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Time: 0.184, Train loss: 0.137\n",
      "Epoch 1. Time: 0.162, Train loss: 0.021\n",
      "Epoch 2. Time: 0.152, Train loss: 0.009\n",
      "Epoch 3. Time: 0.166, Train loss: 0.005\n",
      "Epoch 4. Time: 0.149, Train loss: 0.003\n",
      "Epoch 5. Time: 0.149, Train loss: 0.002\n",
      "Epoch 6. Time: 0.151, Train loss: 0.001\n",
      "Epoch 7. Time: 0.150, Train loss: 0.001\n",
      "Epoch 8. Time: 0.152, Train loss: 0.001\n",
      "Epoch 9. Time: 0.150, Train loss: 0.001\n",
      "Epoch 10. Time: 0.152, Train loss: 0.000\n",
      "Epoch 11. Time: 0.154, Train loss: 0.000\n",
      "Epoch 12. Time: 0.152, Train loss: 0.000\n",
      "Epoch 13. Time: 0.153, Train loss: 0.000\n",
      "Epoch 14. Time: 0.152, Train loss: 0.000\n",
      "Epoch 15. Time: 0.155, Train loss: 0.000\n",
      "Epoch 16. Time: 0.156, Train loss: 0.000\n",
      "Epoch 17. Time: 0.154, Train loss: 0.000\n",
      "Epoch 18. Time: 0.155, Train loss: 0.000\n",
      "Epoch 19. Time: 0.154, Train loss: 0.000\n"
     ]
    }
   ],
   "source": [
    "for ep in range(20):\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    train_loss = 0.\n",
    "    train_passed = 0\n",
    "\n",
    "    for i in range(int(len(X) / 100)):\n",
    "        # берём батч в 100 элементов\n",
    "        batch_X= X[i * 10:(i + 1) * 10]\n",
    "        batch_Y= Y[i * 10:(i + 1) * 10]\n",
    "        X_batch = batch_X\n",
    "        Y_batch = batch_Y.flatten()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        answers = model.forward(X_batch)\n",
    "        answers = answers.view(-1, len(CHAR_TO_INDEX))\n",
    "        loss = criterion(answers, Y_batch)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_passed += 1\n",
    "\n",
    "    print(\"Epoch {}. Time: {:.3f}, Train loss: {:.3f}\".format(ep, time.time() - start, train_loss / train_passed))\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'сткдзф'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 'привет'\n",
    "test = caesar_cipher(test, shift)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим качество дешифровки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вход: сткдзф\n",
      "Дешифровка: привет\n"
     ]
    }
   ],
   "source": [
    "def decode_sequence(model, input_sequence):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.tensor([[CHAR_TO_INDEX[char] for char in input_sequence]], dtype=torch.long).to(device)\n",
    "        output = model(input_tensor)\n",
    "        _, predicted_indices = torch.max(output, 2)\n",
    "        decoded_sequence = ''.join([INDEX_TO_CHAR[idx.item()] for idx in predicted_indices[0]])\n",
    "    return decoded_sequence\n",
    "\n",
    "# Пример использования\n",
    "input_sequence = \"сткдзф\"\n",
    "decoded_sequence = decode_sequence(model, input_sequence)\n",
    "print(f\"Вход: {input_sequence}\")\n",
    "print(f\"Дешифровка: {decoded_sequence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Датасет Симпсоны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79169\\AppData\\Local\\Temp\\ipykernel_37476\\2128749798.py:1: DtypeWarning: Columns (4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r'C:\\Users\\79169\\Desktop\\домашка\\DLL\\simpsons_script_lines.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>number</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>timestamp_in_ms</th>\n",
       "      <th>speaking_line</th>\n",
       "      <th>character_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>raw_location_text</th>\n",
       "      <th>spoken_words</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9549</td>\n",
       "      <td>32</td>\n",
       "      <td>209</td>\n",
       "      <td>Miss Hoover: No, actually, it was a little of ...</td>\n",
       "      <td>848000</td>\n",
       "      <td>True</td>\n",
       "      <td>464.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "      <td>no actually it was a little of both sometimes ...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9550</td>\n",
       "      <td>32</td>\n",
       "      <td>210</td>\n",
       "      <td>Lisa Simpson: (NEAR TEARS) Where's Mr. Bergstrom?</td>\n",
       "      <td>856000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "      <td>wheres mr bergstrom</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9551</td>\n",
       "      <td>32</td>\n",
       "      <td>211</td>\n",
       "      <td>Miss Hoover: I don't know. Although I'd sure l...</td>\n",
       "      <td>856000</td>\n",
       "      <td>True</td>\n",
       "      <td>464.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "      <td>i dont know although id sure like to talk to h...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9552</td>\n",
       "      <td>32</td>\n",
       "      <td>212</td>\n",
       "      <td>Lisa Simpson: That life is worth living.</td>\n",
       "      <td>864000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>That life is worth living.</td>\n",
       "      <td>that life is worth living</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9553</td>\n",
       "      <td>32</td>\n",
       "      <td>213</td>\n",
       "      <td>Edna Krabappel-Flanders: The polls will be ope...</td>\n",
       "      <td>864000</td>\n",
       "      <td>True</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Edna Krabappel-Flanders</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>The polls will be open from now until the end ...</td>\n",
       "      <td>the polls will be open from now until the end ...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158266</th>\n",
       "      <td>9544</td>\n",
       "      <td>32</td>\n",
       "      <td>204</td>\n",
       "      <td>Miss Hoover: (OFF LISA'S REACTION) I'm back.</td>\n",
       "      <td>831000</td>\n",
       "      <td>true</td>\n",
       "      <td>464</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>I'm back.</td>\n",
       "      <td>im back</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158267</th>\n",
       "      <td>9545</td>\n",
       "      <td>32</td>\n",
       "      <td>205</td>\n",
       "      <td>Miss Hoover: You see, class, my Lyme disease t...</td>\n",
       "      <td>839000</td>\n",
       "      <td>true</td>\n",
       "      <td>464</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>You see, class, my Lyme disease turned out to ...</td>\n",
       "      <td>you see class my lyme disease turned out to be</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158268</th>\n",
       "      <td>9546</td>\n",
       "      <td>32</td>\n",
       "      <td>206</td>\n",
       "      <td>Miss Hoover: Psy-cho-so-ma-tic.</td>\n",
       "      <td>842000</td>\n",
       "      <td>true</td>\n",
       "      <td>464</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>Psy-cho-so-ma-tic.</td>\n",
       "      <td>psy-cho-so-ma-tic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158269</th>\n",
       "      <td>9547</td>\n",
       "      <td>32</td>\n",
       "      <td>207</td>\n",
       "      <td>Ralph Wiggum: Does that mean you were crazy?</td>\n",
       "      <td>844000</td>\n",
       "      <td>true</td>\n",
       "      <td>119</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Ralph Wiggum</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>Does that mean you were crazy?</td>\n",
       "      <td>does that mean you were crazy</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158270</th>\n",
       "      <td>9548</td>\n",
       "      <td>32</td>\n",
       "      <td>208</td>\n",
       "      <td>JANEY: No, that means she was faking it.</td>\n",
       "      <td>845000</td>\n",
       "      <td>true</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>JANEY</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>No, that means she was faking it.</td>\n",
       "      <td>no that means she was faking it</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158271 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  episode_id  number  \\\n",
       "0       9549          32     209   \n",
       "1       9550          32     210   \n",
       "2       9551          32     211   \n",
       "3       9552          32     212   \n",
       "4       9553          32     213   \n",
       "...      ...         ...     ...   \n",
       "158266  9544          32     204   \n",
       "158267  9545          32     205   \n",
       "158268  9546          32     206   \n",
       "158269  9547          32     207   \n",
       "158270  9548          32     208   \n",
       "\n",
       "                                                 raw_text timestamp_in_ms  \\\n",
       "0       Miss Hoover: No, actually, it was a little of ...          848000   \n",
       "1       Lisa Simpson: (NEAR TEARS) Where's Mr. Bergstrom?          856000   \n",
       "2       Miss Hoover: I don't know. Although I'd sure l...          856000   \n",
       "3                Lisa Simpson: That life is worth living.          864000   \n",
       "4       Edna Krabappel-Flanders: The polls will be ope...          864000   \n",
       "...                                                   ...             ...   \n",
       "158266       Miss Hoover: (OFF LISA'S REACTION) I'm back.          831000   \n",
       "158267  Miss Hoover: You see, class, my Lyme disease t...          839000   \n",
       "158268                    Miss Hoover: Psy-cho-so-ma-tic.          842000   \n",
       "158269       Ralph Wiggum: Does that mean you were crazy?          844000   \n",
       "158270           JANEY: No, that means she was faking it.          845000   \n",
       "\n",
       "       speaking_line character_id  location_id       raw_character_text  \\\n",
       "0               True        464.0          3.0              Miss Hoover   \n",
       "1               True          9.0          3.0             Lisa Simpson   \n",
       "2               True        464.0          3.0              Miss Hoover   \n",
       "3               True          9.0          3.0             Lisa Simpson   \n",
       "4               True         40.0          3.0  Edna Krabappel-Flanders   \n",
       "...              ...          ...          ...                      ...   \n",
       "158266          true          464          3.0              Miss Hoover   \n",
       "158267          true          464          3.0              Miss Hoover   \n",
       "158268          true          464          3.0              Miss Hoover   \n",
       "158269          true          119          3.0             Ralph Wiggum   \n",
       "158270          true            4          3.0                    JANEY   \n",
       "\n",
       "                    raw_location_text  \\\n",
       "0       Springfield Elementary School   \n",
       "1       Springfield Elementary School   \n",
       "2       Springfield Elementary School   \n",
       "3       Springfield Elementary School   \n",
       "4       Springfield Elementary School   \n",
       "...                               ...   \n",
       "158266  Springfield Elementary School   \n",
       "158267  Springfield Elementary School   \n",
       "158268  Springfield Elementary School   \n",
       "158269  Springfield Elementary School   \n",
       "158270  Springfield Elementary School   \n",
       "\n",
       "                                             spoken_words  \\\n",
       "0       No, actually, it was a little of both. Sometim...   \n",
       "1                                  Where's Mr. Bergstrom?   \n",
       "2       I don't know. Although I'd sure like to talk t...   \n",
       "3                              That life is worth living.   \n",
       "4       The polls will be open from now until the end ...   \n",
       "...                                                   ...   \n",
       "158266                                          I'm back.   \n",
       "158267  You see, class, my Lyme disease turned out to ...   \n",
       "158268                                 Psy-cho-so-ma-tic.   \n",
       "158269                     Does that mean you were crazy?   \n",
       "158270                  No, that means she was faking it.   \n",
       "\n",
       "                                          normalized_text word_count  \n",
       "0       no actually it was a little of both sometimes ...         31  \n",
       "1                                     wheres mr bergstrom          3  \n",
       "2       i dont know although id sure like to talk to h...         22  \n",
       "3                               that life is worth living          5  \n",
       "4       the polls will be open from now until the end ...         33  \n",
       "...                                                   ...        ...  \n",
       "158266                                            im back          2  \n",
       "158267     you see class my lyme disease turned out to be         10  \n",
       "158268                                  psy-cho-so-ma-tic          1  \n",
       "158269                      does that mean you were crazy          6  \n",
       "158270                    no that means she was faking it          7  \n",
       "\n",
       "[158271 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\79169\\Desktop\\домашка\\DLL\\simpsons_script_lines.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no actually it was a little of both sometimes when a disease is in all the magazines and all the news shows its only natural that you think you have it',\n",
       " 'wheres mr bergstrom',\n",
       " 'i dont know although id sure like to talk to him he didnt touch my lesson plan what did he teach you',\n",
       " 'that life is worth living',\n",
       " 'the polls will be open from now until the end of recess now just in case any of you have decided to put any thought into this well have our final statements martin',\n",
       " 'i dont think theres anything left to say',\n",
       " 'bart',\n",
       " 'victory party under the slide',\n",
       " nan,\n",
       " 'mr bergstrom mr bergstrom']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases = df['normalized_text'].tolist()  # колонка с предобработанными текстами\n",
    "phrases[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132087"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [[c for c in ph] for ph in phrases if type(ph) is str]\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARS = set('abcdefghijklmnopqrstuvwxyz ')  # все символы, которые мы хотим использовать для кодировки = наш словарь\n",
    "INDEX_TO_CHAR = ['none'] + [w for w in CHARS]  # все неизвестные символы будут получать тег none\n",
    "CHAR_TO_INDEX = {w: i for i, w in enumerate(INDEX_TO_CHAR)}  # словарь токен-индекс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 50  # мы хотим ограничить максимальную длину ввода\n",
    "X = torch.zeros((len(text), MAX_LEN), dtype=int)  # создаём пустой вектор для текста, чтобы класть в него индексы токенов\n",
    "for i in range(len(text)):  # для каждого предложения\n",
    "    for j, w in enumerate(text[i]):  # для каждого токена\n",
    "        if j >= MAX_LEN:\n",
    "            break\n",
    "        X[i, j] = CHAR_TO_INDEX.get(w, CHAR_TO_INDEX['none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([132087, 50])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.nn.Embedding(len(INDEX_TO_CHAR), 28)  # размер словаря * размер вектора для кодировки каждого слова\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим RNN-ячейку на основе полносвязных слоев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(CustomRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        # Зададим веса для входа\n",
    "        self.W_ih = nn.Linear(input_size, hidden_size)\n",
    "        # Зададим веса для скрытого состояния\n",
    "        self.W_hh = nn.Linear(hidden_size, hidden_size)\n",
    "        # Веса для выхода\n",
    "        self.W_ho = nn.Linear(hidden_size, hidden_size)\n",
    "    \n",
    "    def forward(self, x, prev_hidden=None):\n",
    "        batch_size = x.size(0)\n",
    "        if prev_hidden is None:\n",
    "                prev_hidden = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "        x = x.view(batch_size, -1, self.input_size)\n",
    "            # Рассчитываем скрытое состояние\n",
    "        prev_hidden = prev_hidden.view(batch_size, -1, self.hidden_size)\n",
    "        hidden = torch.tanh(self.W_ih(x) + self.W_hh(prev_hidden))\n",
    "        hidden = hidden.view(batch_size, -1, self.hidden_size)\n",
    "            # Вычисляем выход\n",
    "        output = self.W_ho(hidden)\n",
    "        return output, hidden\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обновим сеть из лекции нашей ячейкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(28, 30)\n",
    "        self.rnn = CustomRNN(30, 128).to(device)  # Используем вашу реализацию RNN-ячейки\n",
    "        self.out = torch.nn.Linear(128, 28)\n",
    "\n",
    "    def forward(self, sentences, state=None):\n",
    "        x = self.embedding(sentences)\n",
    "        x, s = self.rnn(x) # берём выход с последнего слоя для всех токенов, а не скрытое состояние\n",
    "        return self.out(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()  # типичный лосс многоклассовой классификации\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "X = X.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Time: 2.364, Train loss: 1.811\n",
      "Epoch 1. Time: 2.245, Train loss: 1.714\n",
      "Epoch 2. Time: 2.153, Train loss: 1.702\n",
      "Epoch 3. Time: 2.212, Train loss: 1.696\n",
      "Epoch 4. Time: 2.161, Train loss: 1.693\n",
      "Epoch 5. Time: 2.169, Train loss: 1.691\n",
      "Epoch 6. Time: 2.120, Train loss: 1.689\n",
      "Epoch 7. Time: 2.244, Train loss: 1.688\n",
      "Epoch 8. Time: 2.602, Train loss: 1.688\n",
      "Epoch 9. Time: 2.173, Train loss: 1.687\n",
      "Epoch 10. Time: 2.174, Train loss: 1.687\n",
      "Epoch 11. Time: 2.144, Train loss: 1.687\n",
      "Epoch 12. Time: 2.157, Train loss: 1.686\n",
      "Epoch 13. Time: 2.131, Train loss: 1.686\n",
      "Epoch 14. Time: 2.165, Train loss: 1.686\n",
      "Epoch 15. Time: 2.154, Train loss: 1.686\n",
      "Epoch 16. Time: 2.168, Train loss: 1.686\n",
      "Epoch 17. Time: 2.189, Train loss: 1.686\n",
      "Epoch 18. Time: 2.243, Train loss: 1.686\n",
      "Epoch 19. Time: 2.160, Train loss: 1.686\n"
     ]
    }
   ],
   "source": [
    "for ep in range(20):\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    train_loss = 0.\n",
    "    train_passed = 0\n",
    "\n",
    "    for i in range(int(len(X) / 100)):\n",
    "        # берём батч в 100 элементов\n",
    "        batch = X[i * 100:(i + 1) * 100]\n",
    "        X_batch = batch[:, :-1]\n",
    "        Y_batch = batch[:, 1:].flatten()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        X_batch = X_batch.to(device)\n",
    "        Y_batch = Y_batch.to(device)\n",
    "        answers = model.forward(X_batch)\n",
    "        answers = answers.view(-1, len(INDEX_TO_CHAR))\n",
    "        loss = criterion(answers , Y_batch)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_passed += 1\n",
    "\n",
    "    print(\"Epoch {}. Time: {:.3f}, Train loss: {:.3f}\".format(ep, time.time() - start, train_loss / train_passed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHAR_TO_INDEX['none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(word):\n",
    "    sentence = list(word)\n",
    "    sentence = [CHAR_TO_INDEX.get(s, 0) for s in sentence]\n",
    "    input_tensor = torch.tensor(sentence).to(device)\n",
    "    model.eval()\n",
    "    answers = model.forward(torch.tensor(input_tensor))\n",
    "    probas, indices = answers.topk(1)\n",
    "    return ''.join([INDEX_TO_CHAR[ind.item()] for ind in indices.flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79169\\AppData\\Local\\Temp\\ipykernel_37476\\4130102354.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  answers = model.forward(torch.tensor(input_tensor))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' u '"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79169\\AppData\\Local\\Temp\\ipykernel_37476\\4130102354.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  answers = model.forward(torch.tensor(input_tensor))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'none tn '"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence('It is')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
