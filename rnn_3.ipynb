{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "import io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "# объект, который позволит работать с языком\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name # сохраняется имя\n",
    "        self.word2index = {} # словарь для маппинга слов в индексы.\n",
    "        self.word2count = {} # словарь для подсчета количества встреченных слов.\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"} # словарь для маппинга индексов обратно в слова. Изначально содержит специальные токены SOS и EOS\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):#Метод добавления предложения \n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word): #Метод добавления слова \n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):#принимает строку s и возвращает ее ASCII-представление, удаляя диакритические знаки (акценты, тильды и т. д.)\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def normalizeString(s):# принимает строку s и возвращает нормализованную версию этой строки.\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = s.lower()\n",
    "    s = re.sub('[.!?]','',s)\n",
    "    #s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    #s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('C:\\\\Users\\\\79169\\\\Desktop\\\\домашка\\\\DLL\\\\%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    lines = [i.split('\\tCC-BY', 1)[0] for i in lines]\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 487600 sentence pairs\n",
      "Trimmed to 4679 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "rus 4305\n",
      "eng 2236\n",
      "['она помогает своеи семье', 'she supports her family']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'rus', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 46s (- 10m 54s) (5000 6%) 3.1670\n",
      "1m 28s (- 9m 36s) (10000 13%) 2.6093\n",
      "2m 10s (- 8m 43s) (15000 20%) 2.1472\n",
      "2m 53s (- 7m 57s) (20000 26%) 1.7402\n",
      "3m 36s (- 7m 13s) (25000 33%) 1.3364\n",
      "4m 20s (- 6m 30s) (30000 40%) 1.0451\n",
      "5m 4s (- 5m 47s) (35000 46%) 0.8442\n",
      "5m 47s (- 5m 4s) (40000 53%) 0.6275\n",
      "6m 31s (- 4m 21s) (45000 60%) 0.4694\n",
      "7m 16s (- 3m 38s) (50000 66%) 0.3370\n",
      "8m 1s (- 2m 55s) (55000 73%) 0.2621\n",
      "8m 46s (- 2m 11s) (60000 80%) 0.1948\n",
      "9m 30s (- 1m 27s) (65000 86%) 0.1383\n",
      "10m 14s (- 0m 43s) (70000 93%) 0.0989\n",
      "10m 59s (- 0m 0s) (75000 100%) 0.0891\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "trainIters(encoder1, decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> это вопросы, которые нам нужно обсудить\n",
      "= they are matters which we need to discuss\n",
      "< they are matters which we are sinners <EOS>\n",
      "\n",
      "> она тихая женщина\n",
      "= she is a quiet woman\n",
      "< she is a quiet woman <EOS>\n",
      "\n",
      "> он сеичас пьет кофе\n",
      "= he is having coffee now\n",
      "< he is having coffee now <EOS>\n",
      "\n",
      "> он высок и кажется сильным\n",
      "= he is tall and looks strong\n",
      "< he is tall and looks strong <EOS>\n",
      "\n",
      "> я устала это слышать\n",
      "= i am tired of hearing it\n",
      "< i am tired of hearing it <EOS>\n",
      "\n",
      "> он умнее меня\n",
      "= he is more clever than me\n",
      "< he is more clever than i am <EOS>\n",
      "\n",
      "> он рад слышать эти известия\n",
      "= he is glad to hear the news\n",
      "< he is glad to hear the news <EOS>\n",
      "\n",
      "> она пытается похудеть\n",
      "= she is trying to lose weight\n",
      "< she is trying to lose weight <EOS>\n",
      "\n",
      "> вы ведь хладнокровныи человек\n",
      "= you are a cold-blooded person, aren't you\n",
      "< you are a cold-blooded person, aren't you <EOS>\n",
      "\n",
      "> он совсем не боится змеи\n",
      "= he is not scared of snakes at all\n",
      "< he is not scared of snakes at all <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим слои в энкодер и декодер и посмотрим что получится"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(EncoderRNN2, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size,  num_layers=num_layers)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(num_layers, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN2(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, num_layers):\n",
    "        super(DecoderRNN2, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size,num_layers=num_layers)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(num_layers, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 59s (- 13m 47s) (5000 6%) 3.1723\n",
      "1m 57s (- 12m 41s) (10000 13%) 2.8005\n",
      "2m 52s (- 11m 31s) (15000 20%) 2.4617\n",
      "3m 49s (- 10m 31s) (20000 26%) 2.0881\n",
      "4m 47s (- 9m 34s) (25000 33%) 1.6691\n",
      "5m 43s (- 8m 35s) (30000 40%) 1.3347\n",
      "6m 40s (- 7m 38s) (35000 46%) 1.0174\n",
      "7m 36s (- 6m 39s) (40000 53%) 0.8014\n",
      "8m 30s (- 5m 40s) (45000 60%) 0.6114\n",
      "9m 24s (- 4m 42s) (50000 66%) 0.4639\n",
      "10m 19s (- 3m 45s) (55000 73%) 0.3274\n",
      "11m 13s (- 2m 48s) (60000 80%) 0.2533\n",
      "12m 10s (- 1m 52s) (65000 86%) 0.1627\n",
      "13m 6s (- 0m 56s) (70000 93%) 0.1273\n",
      "14m 2s (- 0m 0s) (75000 100%) 0.1040\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN2(input_lang.n_words, hidden_size,num_layers).to(device)\n",
    "decoder1 = DecoderRNN2(hidden_size, output_lang.n_words,num_layers).to(device)\n",
    "\n",
    "trainIters(encoder1, decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> у нее есть брат-близнец\n",
      "= she is a twin\n",
      "< she is a twin <EOS>\n",
      "\n",
      "> я уверен, что у него получится\n",
      "= i am sure that he will succeed\n",
      "< i am sure that he will succeed <EOS>\n",
      "\n",
      "> вам здесь рады\n",
      "= you are welcome here\n",
      "< you are welcome here <EOS>\n",
      "\n",
      "> ты несешь ответственность за результат\n",
      "= you are responsible for the result\n",
      "< you are responsible for the result <EOS>\n",
      "\n",
      "> мне стыдно за свои плохои англиискии\n",
      "= i am ashamed of my poor english\n",
      "< i am ashamed of my poor english <EOS>\n",
      "\n",
      "> он честныи человек\n",
      "= he is an honest man\n",
      "< he is an honest man <EOS>\n",
      "\n",
      "> он купается в реке\n",
      "= he is swimming in the river\n",
      "< he is swimming in the river <EOS>\n",
      "\n",
      "> у нее есть привычка ходить на пробежку перед завтраком\n",
      "= she is in the habit of jogging before breakfast\n",
      "< she is in the habit of jogging before breakfast <EOS>\n",
      "\n",
      "> она гордится своими сыновьями\n",
      "= she is proud of her sons\n",
      "< she is proud of her sons <EOS>\n",
      "\n",
      "> он не тупои\n",
      "= he is not stupid\n",
      "< he is not dumb <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь видим, что в последнем словосочетании был подобран синоним "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем с LSTM с 1 слоем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers \n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size,  num_layers=num_layers)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(self.num_layers, 1, self.hidden_size, device=device),\n",
    "                torch.zeros(self.num_layers, 1, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, num_layers):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size,num_layers=num_layers)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(self.num_layers, 1, self.hidden_size, device=device),\n",
    "                torch.zeros(self.num_layers, 1, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train1(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden() #Инициализация скрытого состояния энкодера\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0) # Получение длины входного и \n",
    "    target_length = target_tensor.size(0) #и целевого тензоров. \n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)#Инициализация тензора decoder_input с начальным символом (SOS).\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters1(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 48s (- 11m 22s) (5000 6%) 3.2538\n",
      "1m 33s (- 10m 6s) (10000 13%) 2.8546\n",
      "2m 21s (- 9m 25s) (15000 20%) 2.5009\n",
      "3m 9s (- 8m 40s) (20000 26%) 2.1215\n",
      "3m 58s (- 7m 56s) (25000 33%) 1.7617\n",
      "4m 47s (- 7m 10s) (30000 40%) 1.4632\n",
      "5m 36s (- 6m 24s) (35000 46%) 1.1829\n",
      "6m 25s (- 5m 37s) (40000 53%) 0.9521\n",
      "7m 14s (- 4m 49s) (45000 60%) 0.7440\n",
      "8m 3s (- 4m 1s) (50000 66%) 0.5908\n",
      "8m 52s (- 3m 13s) (55000 73%) 0.4673\n",
      "9m 38s (- 2m 24s) (60000 80%) 0.3693\n",
      "10m 24s (- 1m 36s) (65000 86%) 0.2728\n",
      "11m 11s (- 0m 47s) (70000 93%) 0.2201\n",
      "11m 57s (- 0m 0s) (75000 100%) 0.1781\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderLSTM(input_lang.n_words, hidden_size,num_layers).to(device)\n",
    "decoder1 = DecoderLSTM(hidden_size, output_lang.n_words,num_layers).to(device)\n",
    "\n",
    "trainIters1(encoder1, decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> он — то, что мы называем музыкальным гением\n",
      "= he is what we call a musical genius\n",
      "< he is what we call a musical genius <EOS>\n",
      "\n",
      "> боюсь, он не придет\n",
      "= i am afraid he won't come\n",
      "< i am afraid he won't come <EOS>\n",
      "\n",
      "> он ответственен за это\n",
      "= he is responsible for it\n",
      "< he is responsible for it <EOS>\n",
      "\n",
      "> он официант и актер к тому же\n",
      "= he is a waiter and also an actor\n",
      "< he is a waiter and also an actor <EOS>\n",
      "\n",
      "> можете идти домои\n",
      "= you are free to go home\n",
      "< you are free to go home <EOS>\n",
      "\n",
      "> я самыи счастливыи человек на земле\n",
      "= i am the happiest man on earth\n",
      "< i am the happiest man on earth <EOS>\n",
      "\n",
      "> он активныи человек\n",
      "= he is an active person\n",
      "< he is an active person <EOS>\n",
      "\n",
      "> мне шестнадцать лет\n",
      "= i am sixteen years old\n",
      "< i am sixteen years old <EOS>\n",
      "\n",
      "> она говорит на десяти языках\n",
      "= she speaks ten languages\n",
      "< she speaks ten languages <EOS>\n",
      "\n",
      "> вы что, не слушаете\n",
      "= you aren't listening, are you\n",
      "< you aren't listening, are you <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все четко переведено"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем с 2 слоями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 0s (- 14m 6s) (5000 6%) 3.3577\n",
      "1m 55s (- 12m 31s) (10000 13%) 3.0439\n",
      "2m 55s (- 11m 43s) (15000 20%) 2.8477\n",
      "3m 55s (- 10m 46s) (20000 26%) 2.5709\n",
      "4m 54s (- 9m 49s) (25000 33%) 2.2525\n",
      "5m 51s (- 8m 47s) (30000 40%) 1.9742\n",
      "6m 50s (- 7m 49s) (35000 46%) 1.7014\n",
      "7m 50s (- 6m 51s) (40000 53%) 1.4338\n",
      "8m 51s (- 5m 54s) (45000 60%) 1.1943\n",
      "9m 54s (- 4m 57s) (50000 66%) 0.9878\n",
      "10m 56s (- 3m 58s) (55000 73%) 0.7551\n",
      "12m 0s (- 3m 0s) (60000 80%) 0.6276\n",
      "13m 3s (- 2m 0s) (65000 86%) 0.5006\n",
      "14m 3s (- 1m 0s) (70000 93%) 0.3703\n",
      "15m 4s (- 0m 0s) (75000 100%) 0.2917\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderLSTM(input_lang.n_words, hidden_size,num_layers).to(device)\n",
    "decoder1 = DecoderLSTM(hidden_size, output_lang.n_words,num_layers).to(device)\n",
    "\n",
    "trainIters1(encoder1, decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> она может обучать англиискому\n",
      "= she is capable of teaching english\n",
      "< she is capable of teaching english <EOS>\n",
      "\n",
      "> я очень устала от плавания\n",
      "= i am very tired from swimming\n",
      "< i am very tired from swimming <EOS>\n",
      "\n",
      "> я готов начать\n",
      "= i am ready to start\n",
      "< i am ready to start <EOS>\n",
      "\n",
      "> он странныи, а я не люблю странных людеи\n",
      "= he is strange, and i don't like strange people\n",
      "< he is strange, and i don't like strange <EOS>\n",
      "\n",
      "> ты не сумасшедшии\n",
      "= you aren't crazy\n",
      "< you aren't crazy <EOS>\n",
      "\n",
      "> она с ним сурова\n",
      "= she is hard on him\n",
      "< she is hard on him <EOS>\n",
      "\n",
      "> говорят, что он убиица\n",
      "= he is allegedly the murderer\n",
      "< he is allegedly the murderer <EOS>\n",
      "\n",
      "> ему не хватает здравого смысла\n",
      "= he is lacking in common sense\n",
      "< he is lacking in common sense <EOS>\n",
      "\n",
      "> он последнии человек, которого я хочу видеть\n",
      "= he is the last man i want to see\n",
      "< he is the last man i want to see <EOS>\n",
      "\n",
      "> они разговаривают на кухне\n",
      "= they are talking in the kitchen\n",
      "< they are talking in the kitchen <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 предложение он до конца не перевел"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем обучение батчами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTMb(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(EncoderLSTMb, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers \n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = embedded.view(1, input.size(0), -1)  # Adjust dimensions for batch processing\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device),\n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLSTMb(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, num_layers):\n",
    "        super(DecoderLSTMb, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size,num_layers=num_layers)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device),\n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH, teacher_forcing_ratio=0.5):\n",
    "    batch_size = input_tensor.size(1)\n",
    "    encoder_hidden = encoder.initHidden(batch_size)\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length, batch_size = input_tensor.size()\n",
    "    target_length, _ = target_tensor.size()\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, batch_size, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei].view(1, batch_size), encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]] * batch_size, device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainItersb(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train_batch(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 59s (- 13m 52s) (5000 6%) 3.4426\n",
      "1m 55s (- 12m 28s) (10000 13%) 3.0270\n",
      "2m 49s (- 11m 18s) (15000 20%) 2.8477\n",
      "3m 45s (- 10m 18s) (20000 26%) 2.5791\n",
      "4m 40s (- 9m 21s) (25000 33%) 2.2990\n",
      "5m 40s (- 8m 30s) (30000 40%) 2.0158\n",
      "6m 37s (- 7m 34s) (35000 46%) 1.6896\n",
      "7m 33s (- 6m 37s) (40000 53%) 1.4331\n",
      "8m 32s (- 5m 41s) (45000 60%) 1.1765\n",
      "9m 30s (- 4m 45s) (50000 66%) 1.0045\n",
      "10m 30s (- 3m 49s) (55000 73%) 0.8019\n",
      "11m 28s (- 2m 52s) (60000 80%) 0.6070\n",
      "12m 25s (- 1m 54s) (65000 86%) 0.4967\n",
      "13m 21s (- 0m 57s) (70000 93%) 0.3875\n",
      "14m 17s (- 0m 0s) (75000 100%) 0.2993\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderLSTMb(input_lang.n_words, hidden_size,num_layers).to(device)\n",
    "decoder1 = DecoderLSTMb(hidden_size, output_lang.n_words,num_layers).to(device)\n",
    "\n",
    "trainItersb(encoder1, decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]#Получение длины входного тензора\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)#Инициализация тензора encoder_outputs, который будет содержать выходные данные энкодера. Размерность этого тензора - (max_length, encoder.hidden_size).\n",
    "\n",
    "        for ei in range(input_length): #Цикл по всем элементам входного тензора.\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], #Подача текущего элемента входного тензора в энкодер, получение выхода и обновление скрытого состояния энкодера.\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device).repeat(1, 1)  # Создание тензора decoder_input с начальным символом (SOS) и повторение его для размера пакета 1\n",
    "        decoder_input = decoder_input.view(1, 1, -1) #Изменение формы decoder_input на (1, 1, -1), где -1 означает автоматическое вычисление размерности.\n",
    "\n",
    "        decoder_hidden = encoder_hidden #Инициализация скрытого состояния декодера скрытым состоянием энкодера\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length): #Цикл по максимальной длине (максимальному количеству шагов декодирования).\n",
    "            decoder_output, decoder_hidden = decoder( #Подача текущего входа декодера и скрытого состояния, получение выхода и обновление скрытого состояния декодера\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1) # Получение индекса и значения наивысшего элемента в выходном тензоре декодера.\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach() #Обновляем вход декодера на основе индекса текущего вывода и отсоединяем его от графа вычислений.\n",
    "\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ты не такая молодая, как я\n",
      "= you aren't as young as i am\n",
      "< you aren't as young as i am <EOS>\n",
      "\n",
      "> он ждет телефонного звонка\n",
      "= he is waiting for a telephone call\n",
      "< he is waiting for a telephone <EOS>\n",
      "\n",
      "> он самыи богатыи человек в мире\n",
      "= he is the richest man on earth\n",
      "< he is the tallest person in <EOS>\n",
      "\n",
      "> она определенно удивится\n",
      "= she is certain to be surprised\n",
      "< she is certain to be surprised <EOS>\n",
      "\n",
      "> она учительница\n",
      "= she is a teacher\n",
      "< she is a teacher <EOS>\n",
      "\n",
      "> ты теперь взрослая\n",
      "= you are now an adult\n",
      "< you are now an adult <EOS>\n",
      "\n",
      "> он планирует развивать свое дело\n",
      "= he is planning to develop his business\n",
      "< he is planning to his his business <EOS>\n",
      "\n",
      "> они не двоиняшки\n",
      "= they aren't twins\n",
      "< they aren't twins <EOS>\n",
      "\n",
      "> он невиновен в преступлении\n",
      "= he is innocent of the crime\n",
      "< he is innocent of the crime <EOS>\n",
      "\n",
      "> он не такои строгии, как наш учитель\n",
      "= he is less strict than our teacher\n",
      "< he is less strict than our teacher <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что в переводах содержатся ошибки, и для обучения батчами видимо требуется больше времени, чем по элементно;  Также надо отметить, что при увеличении слоев повышается ошибка в переводе при сохранении того же числа эпох. Следовательно их нужно увеличить"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
